{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "import csv\n",
    "import logging\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file):\n",
    "    \"\"\"\n",
    "    Load and preprocess data from a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        file (str): URL or local path to the CSV file containing data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame with one-hot encoded categorical variables and filtered invalid entries.\n",
    "    \"\"\"\n",
    "    diamonds = pd.read_csv(file)\n",
    "    diamonds = diamonds[(diamonds.x * diamonds.y * diamonds.z != 0) & (diamonds.price > 0)]\n",
    "\n",
    "    return diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(diamonds, model_type='linear'):\n",
    "    if model_type == 'linear':\n",
    "        return pd.get_dummies(diamonds, columns=['cut', 'color', 'clarity'], drop_first=True)\n",
    "    elif model_type == 'tree':\n",
    "        for col in ['cut', 'color', 'clarity']:\n",
    "            diamonds[col] = pd.Categorical(diamonds[col])\n",
    "        return pd.get_dummies(diamonds, columns=['cut', 'color', 'clarity'], drop_first=False)\n",
    "    return diamonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.10</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>4733</td>\n",
       "      <td>6.61</td>\n",
       "      <td>6.65</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.29</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>H</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6424</td>\n",
       "      <td>6.96</td>\n",
       "      <td>6.93</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>SI1</td>\n",
       "      <td>61.1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5510</td>\n",
       "      <td>6.88</td>\n",
       "      <td>6.80</td>\n",
       "      <td>4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.50</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.9</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8770</td>\n",
       "      <td>7.43</td>\n",
       "      <td>7.36</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>VS2</td>\n",
       "      <td>61.7</td>\n",
       "      <td>57.0</td>\n",
       "      <td>4493</td>\n",
       "      <td>6.17</td>\n",
       "      <td>6.21</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat        cut color clarity  depth  table  price     x     y     z\n",
       "0   1.10      Ideal     H     SI2   62.0   55.0   4733  6.61  6.65  4.11\n",
       "1   1.29      Ideal     H     SI1   62.6   56.0   6424  6.96  6.93  4.35\n",
       "2   1.20    Premium     I     SI1   61.1   58.0   5510  6.88  6.80  4.18\n",
       "3   1.50      Ideal     F     SI1   60.9   56.0   8770  7.43  7.36  4.50\n",
       "4   0.90  Very Good     F     VS2   61.7   57.0   4493  6.17  6.21  3.82"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = \"https://raw.githubusercontent.com/xtreamsrl/xtream-ai-assignment-engineer/main/datasets/diamonds/diamonds.csv\"\n",
    "data = load_data(data_file) \n",
    "\n",
    "data_linear = preprocess_data(data.copy(), 'linear')\n",
    "data_tree = preprocess_data(data.copy(), 'tree')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    \"\"\"\n",
    "    Split the data into training and testing sets.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The DataFrame to split.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: Contains training and testing datasets (x_train, x_test, y_train, y_test).\n",
    "    \"\"\"\n",
    "    x = data.drop(columns='price')\n",
    "    y = data.price\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_linear, x_test_linear, y_train_linear, y_test_linear = split_data(data_linear)\n",
    "x_train_tree, x_test_tree, y_train_tree, y_test_tree = split_data(data_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a machine learning model.\n",
    "    \n",
    "    Parameters:\n",
    "        model: The machine learning model to be trained.\n",
    "        x_train (pd.DataFrame): Training data features.\n",
    "        y_train (pd.Series): Training data labels.\n",
    "    \n",
    "    Returns:\n",
    "        model: Trained model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        model.fit(x_train, y_train)\n",
    "        logging.info(f\"Training completed successfully for {type(model).__name__}\")\n",
    "\n",
    "        return model\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error training model {type(model).__name__}: {str(e)}\", exc_info=True)\n",
    "        \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate a machine learning model using R2 and MAE.\n",
    "    \n",
    "    Parameters:\n",
    "        model: The trained machine learning model to evaluate.\n",
    "        x_test (pd.DataFrame): Testing data features.\n",
    "        y_test (pd.Series): Testing data labels.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing evaluation metrics.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        predictions = model.predict(x_test)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        logging.info(f\"Evaluation metrics calculated successfully for {type(model).__name__}\")\n",
    "\n",
    "        return {\"R2 Score\": r2, \"MAE\": mae}\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error evaluating model {type(model).__name__}: {str(e)}\", exc_info=True)\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, performance_metrics, model_name):\n",
    "    \"\"\"\n",
    "    Save the model and its performance metrics with a timestamp in a txt file.\n",
    "    \"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S\")\n",
    "    model_directory = f\"models/{model_name}/{timestamp}\"\n",
    "\n",
    "    os.makedirs(model_directory, exist_ok=True)\n",
    "    joblib.dump(model, f\"{model_directory}/model.joblib\")\n",
    "\n",
    "    with open(f\"{model_directory}/metrics.txt\", 'w') as f:\n",
    "        f.write(str(performance_metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(metrics, model_name, filename=\"model_performance.csv\"):\n",
    "    \"\"\"\n",
    "    Log model performance metrics to a CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "        metrics (dict): Dictionary containing the performance metrics.\n",
    "        model_name (str): Name of the model.\n",
    "        filename (str): Name of the CSV file to log the metrics.\n",
    "    \"\"\"\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        fieldnames = ['model_name', 'timestamp', 'R2_score', 'MAE']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        metrics_row = {\n",
    "            'model_name': model_name,\n",
    "            'timestamp': datetime.datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"),\n",
    "            'R2_score': metrics['R2 Score'],\n",
    "            'MAE': metrics['MAE']\n",
    "        }\n",
    "\n",
    "        writer.writerow(metrics_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LinearRegression\": {\"model\": LinearRegression(), \"type\": \"linear\"},\n",
    "    \"Ridge\": {\"model\": Ridge(), \"type\": \"linear\"},\n",
    "    \"Lasso\": {\"model\": Lasso(), \"type\": \"linear\"},\n",
    "    \"ElasticNet\": {\"model\": ElasticNet(), \"type\": \"linear\"},\n",
    "    \"LinearSVR\": {\"model\": LinearSVR(), \"type\": \"linear\"},\n",
    "    \"SGDRegressor\": {\"model\": SGDRegressor(), \"type\": \"linear\"},\n",
    "    \"XGBoost\": {\"model\": xgboost.XGBRegressor(enable_categorical=True, random_state=42), \"type\": \"tree\"}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 00:13:29,745 - INFO - Starting training for LinearRegression\n",
      "2024-07-03 00:13:29,756 - INFO - Training completed successfully for LinearRegression\n",
      "2024-07-03 00:13:29,758 - INFO - Evaluation metrics calculated successfully for LinearRegression\n",
      "2024-07-03 00:13:29,762 - INFO - LinearRegression - R2 Score: 0.9090798105116309, MAE: 756.7317987073\n",
      "2024-07-03 00:13:29,762 - INFO - Starting training for Ridge\n",
      "2024-07-03 00:13:29,765 - INFO - Training completed successfully for Ridge\n",
      "2024-07-03 00:13:29,766 - INFO - Evaluation metrics calculated successfully for Ridge\n",
      "2024-07-03 00:13:29,768 - INFO - Ridge - R2 Score: 0.9089438362670546, MAE: 756.1527571184614\n",
      "2024-07-03 00:13:29,768 - INFO - Starting training for Lasso\n",
      "/Users/luca/Documents/Proyectos personales/xtream-ai-assignment-developer/venv/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.498e+07, tolerance: 6.370e+06\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "2024-07-03 00:13:29,842 - INFO - Training completed successfully for Lasso\n",
      "2024-07-03 00:13:29,844 - INFO - Evaluation metrics calculated successfully for Lasso\n",
      "2024-07-03 00:13:29,845 - INFO - Lasso - R2 Score: 0.9091178731666789, MAE: 750.4417062951571\n",
      "2024-07-03 00:13:29,845 - INFO - Starting training for ElasticNet\n",
      "2024-07-03 00:13:29,849 - INFO - Training completed successfully for ElasticNet\n",
      "2024-07-03 00:13:29,850 - INFO - Evaluation metrics calculated successfully for ElasticNet\n",
      "2024-07-03 00:13:29,851 - INFO - ElasticNet - R2 Score: 0.7924223050511361, MAE: 1186.046956710752\n",
      "2024-07-03 00:13:29,851 - INFO - Starting training for LinearSVR\n",
      "2024-07-03 00:13:29,858 - INFO - Training completed successfully for LinearSVR\n",
      "2024-07-03 00:13:29,860 - INFO - Evaluation metrics calculated successfully for LinearSVR\n",
      "2024-07-03 00:13:29,861 - INFO - LinearSVR - R2 Score: 0.6898330484654562, MAE: 1155.8224278235714\n",
      "2024-07-03 00:13:29,861 - INFO - Starting training for SGDRegressor\n",
      "2024-07-03 00:13:29,890 - INFO - Training completed successfully for SGDRegressor\n",
      "2024-07-03 00:13:29,891 - INFO - Evaluation metrics calculated successfully for SGDRegressor\n",
      "2024-07-03 00:13:29,892 - INFO - SGDRegressor - R2 Score: -2.2254958024776196e+16, MAE: 562489830828.3007\n",
      "2024-07-03 00:13:29,893 - INFO - Starting training for XGBoost\n",
      "2024-07-03 00:13:30,048 - INFO - Training completed successfully for XGBRegressor\n",
      "2024-07-03 00:13:30,052 - INFO - Evaluation metrics calculated successfully for XGBRegressor\n",
      "2024-07-03 00:13:30,054 - INFO - XGBoost - R2 Score: 0.9632148742675781, MAE: 356.4004144152563\n"
     ]
    }
   ],
   "source": [
    "for model_name, config in models.items():\n",
    "    model = config[\"model\"]\n",
    "    model_type = config[\"type\"]\n",
    "\n",
    "    if model_type == \"linear\":\n",
    "        x_train, x_test, y_train, y_test = x_train_linear, x_test_linear, y_train_linear, y_test_linear\n",
    "    elif model_type == \"tree\":\n",
    "        x_train, x_test, y_train, y_test = x_train_tree, x_test_tree, y_train_tree, y_test_tree\n",
    "\n",
    "    logging.info(f\"Starting training for {model_name}\")\n",
    "    trained_model = train_model(model, x_train, y_train)\n",
    "    \n",
    "    if trained_model:\n",
    "        metrics = evaluate_model(trained_model, x_test, y_test)\n",
    "        if metrics:\n",
    "            save_model(trained_model, metrics, model_name)\n",
    "            log_metrics(metrics, model_name)\n",
    "            logging.info(f\"{model_name} - R2 Score: {metrics['R2 Score']}, MAE: {metrics['MAE']}\")\n",
    "        else:\n",
    "            logging.error(f\"Failed to evaluate {model_name}\", exc_info=True)\n",
    "    else:\n",
    "        logging.error(f\"Failed to train {model_name}\", exc_info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data in module __main__:\n",
      "\n",
      "load_data(file)\n",
      "    Load and preprocess data from a CSV file.\n",
      "\n",
      "    Parameters:\n",
      "        file (str): URL or local path to the CSV file containing data.\n",
      "\n",
      "    Returns:\n",
      "        pd.DataFrame: Preprocessed DataFrame with one-hot encoded categorical variables and filtered invalid entries.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split_data in module __main__:\n",
      "\n",
      "split_data(data)\n",
      "    Split the data into training and testing sets.\n",
      "\n",
      "    Parameters:\n",
      "        data (pd.DataFrame): The DataFrame to split.\n",
      "\n",
      "    Returns:\n",
      "        tuple: Contains training and testing datasets (x_train, x_test, y_train, y_test).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(split_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_model in module __main__:\n",
      "\n",
      "train_model(model, x_train, y_train)\n",
      "    Train a machine learning model.\n",
      "\n",
      "    Parameters:\n",
      "        model (estimator): The machine learning model to be trained.\n",
      "        x_train (pd.DataFrame): Training data features.\n",
      "        y_train (pd.Series): Training data labels.\n",
      "\n",
      "    Returns:\n",
      "        model: Trained model.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function evaluate_model in module __main__:\n",
      "\n",
      "evaluate_model(model, x_test, y_test)\n",
      "    Evaluate a machine learning model using R2 and MAE.\n",
      "\n",
      "    Parameters:\n",
      "        model: The trained machine learning model to evaluate.\n",
      "        x_test (pd.DataFrame): Testing data features.\n",
      "        y_test (pd.Series): Testing data labels.\n",
      "\n",
      "    Returns:\n",
      "        dict: Dictionary containing evaluation metrics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(evaluate_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
